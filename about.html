<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>About - Human Annotations Explorer</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <nav class="navbar">
        <div class="nav-container">
            <h1 class="nav-title">Annotations Explorer</h1>
            <ul class="nav-menu">
                <li><a href="index.html" class="nav-link">Home</a></li>
                <li><a href="about.html" class="nav-link">About</a></li>
                <li><a href="explore.html" class="nav-link explore-btn">Explore Annotations</a></li>
            </ul>
        </div>
    </nav>

    <main class="about-page">
        <section class="about">
            <div class="container">
                <h2 class="section-title">About this tool</h2>
                <div class="about-grid">
                    <div class="about-card">
                        <div class="card-icon">üìù</div>
                        <h3>Rich annotations</h3>
                        <p>Each annotation contains detailed source material and summarized content with precisely marked text spans for comprehensive analysis.</p>
                    </div>
                    <div class="about-card">
                        <div class="card-icon">üéØ</div>
                        <h3>Continuous ratings</h3>
                        <p>Every span uses precise 0.0-1.0 scale measurements across evidence strength, likelihood assessment, and consequence evaluation.</p>
                    </div>
                    <div class="about-card">
                        <div class="card-icon">üîç</div>
                        <h3>Interactive exploration</h3>
                        <p>Navigate annotations with side-by-side source and summary views, featuring real-time tooltips and smooth interactions.</p>
                    </div>
                </div>
                
                <div class="methodology">
                    <h3>Rating methodology</h3>
                    <p>Each annotated span includes three key attributes measured on a continuous 0.0-1.0 scale for maximum precision:</p>
                    <ul class="rating-list">
                        <li><strong>Evidence (0.0-1.0):</strong> Measures how well-supported a claim is by available data. Higher values indicate stronger empirical backing and research consensus.</li>
                        <li><strong>Likelihood (0.0-1.0):</strong> Assesses the probability that an annotated claim or event will occur. 0.0 represents highly unlikely scenarios, while 1.0 indicates near certainty.</li>
                        <li><strong>Consequence (0.0-1.0):</strong> Evaluates the potential impact or importance of the annotated content. Higher values signify more significant ramifications for stakeholders.</li>
                    </ul>
                </div>

                <div class="methodology">
                    <h3>Visual indicators</h3>
                    <p>The interface uses intelligently color-coded progress bars to make ratings immediately interpretable:</p>
                    <ul class="rating-list">
                        <li><strong>Evidence bars:</strong> <span style="color: #10b981;">Green</span> indicates high confidence with strong supporting data, <span style="color: #ef4444;">red</span> signals low confidence or weak evidence</li>
                        <li><strong>Likelihood bars:</strong> <span style="color: #ef4444;">Red</span> represents high probability scenarios (potential risks), <span style="color: #10b981;">green</span> shows low probability outcomes</li>
                        <li><strong>Consequence bars:</strong> <span style="color: #ef4444;">Red</span> highlights high-impact scenarios with severe consequences, <span style="color: #10b981;">green</span> indicates minimal impact</li>
                    </ul>
                </div>

                <div class="methodology">
                    <h3>How to use this tool</h3>
                    <div class="usage-steps">
                        <div class="step-card">
                            <div class="step-number">1</div>
                            <div class="step-content">
                                <h4>Select an annotation set</h4>
                                <p>Choose from available annotation collections using the dropdown selector. Each set covers different research domains including climate science, AI development, and economic analysis.</p>
                            </div>
                        </div>
                        <div class="step-card">
                            <div class="step-number">2</div>
                            <div class="step-content">
                                <h4>Compare source and summary</h4>
                                <p>Review the original source document in the left panel alongside the AI-generated summary in the right panel to understand context and identify potential discrepancies.</p>
                            </div>
                        </div>
                        <div class="step-card">
                            <div class="step-number">3</div>
                            <div class="step-content">
                                <h4>Interact with highlighted spans</h4>
                                <p>Click on orange highlighted text segments in the summary to reveal detailed annotations. Each tooltip displays evidence strength, likelihood, and consequence metrics.</p>
                            </div>
                        </div>
                        <div class="step-card">
                            <div class="step-number">4</div>
                            <div class="step-content">
                                <h4>Analyze quantified insights</h4>
                                <p>Use the precise numerical values and color-coded progress bars to assess claim reliability, probability, and potential impact for informed decision-making.</p>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="methodology">
                    <h3>Use cases and applications</h3>
                    <p>This tool serves researchers, analysts, and professionals who require quantified assessment of information quality:</p>
                    <ul class="rating-list">
                        <li><strong>Academic research:</strong> Evaluate evidence strength and claim reliability in research papers, policy documents, and literature reviews</li>
                        <li><strong>Risk assessment:</strong> Quantify both probability and potential consequences of scenarios in business intelligence and strategic planning</li>
                        <li><strong>Information verification:</strong> Distinguish well-supported claims from speculative statements in reports and analyses</li>
                        <li><strong>Decision support:</strong> Use quantified metrics to inform evidence-based decision-making processes across organizations</li>
                    </ul>
                </div>
            </div>
        </section>
    </main>

    <footer class="footer">
        <div class="container">
            <p>&copy; 2025 Human Annotations Explorer. Built for research and analysis.</p>
        </div>
    </footer>

    <script src="script.js"></script>
</body>
</html>